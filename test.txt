7767517
254 266
pnnx.Input               pnnx_input_0             0 1 0 #0=(1,3,320,320)f32
nn.Conv2d                convbn2d_0               1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=24 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(24)f32 @weight=(24,3,3,3)f32 $input=0 #0=(1,3,320,320)f32 #1=(1,24,160,160)f32
nn.LeakyReLU             backbone.conv1.2         1 1 1 2 negative_slope=1.000000e-01 #1=(1,24,160,160)f32 #2=(1,24,160,160)f32
nn.MaxPool2d             backbone.maxpool         1 1 2 3 ceil_mode=False dilation=(1,1) kernel_size=(3,3) padding=(1,1) return_indices=False stride=(2,2) #2=(1,24,160,160)f32 #3=(1,24,80,80)f32
nn.Conv2d                convbn2d_1               1 1 3 4 bias=True dilation=(1,1) groups=24 in_channels=24 kernel_size=(3,3) out_channels=24 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(24)f32 @weight=(24,1,3,3)f32 $input=3 #3=(1,24,80,80)f32 #4=(1,24,40,40)f32
nn.Conv2d                convbn2d_2               1 1 4 5 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,24,1,1)f32 $input=4 #4=(1,24,40,40)f32 #5=(1,58,40,40)f32
nn.LeakyReLU             backbone.stage2.0.branch1.4 1 1 5 6 negative_slope=1.000000e-01 #5=(1,58,40,40)f32 #6=(1,58,40,40)f32
nn.Conv2d                convbn2d_3               1 1 3 7 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,24,1,1)f32 $input=3 #3=(1,24,80,80)f32 #7=(1,58,80,80)f32
nn.LeakyReLU             backbone.stage2.0.branch2.2 1 1 7 8 negative_slope=1.000000e-01 #7=(1,58,80,80)f32 #8=(1,58,80,80)f32
nn.Conv2d                convbn2d_4               1 1 8 9 bias=True dilation=(1,1) groups=58 in_channels=58 kernel_size=(3,3) out_channels=58 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(58)f32 @weight=(58,1,3,3)f32 $input=8 #8=(1,58,80,80)f32 #9=(1,58,40,40)f32
nn.Conv2d                convbn2d_5               1 1 9 10 bias=True dilation=(1,1) groups=1 in_channels=58 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,58,1,1)f32 $input=9 #9=(1,58,40,40)f32 #10=(1,58,40,40)f32
nn.LeakyReLU             backbone.stage2.0.branch2.7 1 1 10 11 negative_slope=1.000000e-01 #10=(1,58,40,40)f32 #11=(1,58,40,40)f32
torch.cat                torch.cat_48             2 1 6 11 12 dim=1 #6=(1,58,40,40)f32 #11=(1,58,40,40)f32 #12=(1,116,40,40)f32
nn.ChannelShuffle        channelshuffle_0         1 1 12 13 groups=2 $input=12 #12=(1,116,40,40)f32 #13=(1,116,40,40)f32
torch.chunk              torch.chunk_77           1 2 13 14 15 chunks=2 dim=1 $input=13 #13=(1,116,40,40)f32 #14=(1,58,40,40)f32 #15=(1,58,40,40)f32
nn.Conv2d                convbn2d_6               1 1 15 16 bias=True dilation=(1,1) groups=1 in_channels=58 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,58,1,1)f32 $input=15 #15=(1,58,40,40)f32 #16=(1,58,40,40)f32
nn.LeakyReLU             backbone.stage2.1.branch2.2 1 1 16 17 negative_slope=1.000000e-01 #16=(1,58,40,40)f32 #17=(1,58,40,40)f32
nn.Conv2d                convbn2d_7               1 1 17 18 bias=True dilation=(1,1) groups=58 in_channels=58 kernel_size=(3,3) out_channels=58 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,1,3,3)f32 $input=17 #17=(1,58,40,40)f32 #18=(1,58,40,40)f32
nn.Conv2d                convbn2d_8               1 1 18 19 bias=True dilation=(1,1) groups=1 in_channels=58 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,58,1,1)f32 $input=18 #18=(1,58,40,40)f32 #19=(1,58,40,40)f32
nn.LeakyReLU             backbone.stage2.1.branch2.7 1 1 19 20 negative_slope=1.000000e-01 #19=(1,58,40,40)f32 #20=(1,58,40,40)f32
torch.cat                torch.cat_49             2 1 14 20 21 dim=1 #14=(1,58,40,40)f32 #20=(1,58,40,40)f32 #21=(1,116,40,40)f32
nn.ChannelShuffle        channelshuffle_1         1 1 21 22 groups=2 $input=21 #21=(1,116,40,40)f32 #22=(1,116,40,40)f32
torch.chunk              torch.chunk_78           1 2 22 23 24 chunks=2 dim=1 $input=22 #22=(1,116,40,40)f32 #23=(1,58,40,40)f32 #24=(1,58,40,40)f32
nn.Conv2d                convbn2d_9               1 1 24 25 bias=True dilation=(1,1) groups=1 in_channels=58 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,58,1,1)f32 $input=24 #24=(1,58,40,40)f32 #25=(1,58,40,40)f32
nn.LeakyReLU             backbone.stage2.2.branch2.2 1 1 25 26 negative_slope=1.000000e-01 #25=(1,58,40,40)f32 #26=(1,58,40,40)f32
nn.Conv2d                convbn2d_10              1 1 26 27 bias=True dilation=(1,1) groups=58 in_channels=58 kernel_size=(3,3) out_channels=58 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,1,3,3)f32 $input=26 #26=(1,58,40,40)f32 #27=(1,58,40,40)f32
nn.Conv2d                convbn2d_11              1 1 27 28 bias=True dilation=(1,1) groups=1 in_channels=58 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,58,1,1)f32 $input=27 #27=(1,58,40,40)f32 #28=(1,58,40,40)f32
nn.LeakyReLU             backbone.stage2.2.branch2.7 1 1 28 29 negative_slope=1.000000e-01 #28=(1,58,40,40)f32 #29=(1,58,40,40)f32
torch.cat                torch.cat_50             2 1 23 29 30 dim=1 #23=(1,58,40,40)f32 #29=(1,58,40,40)f32 #30=(1,116,40,40)f32
nn.ChannelShuffle        channelshuffle_2         1 1 30 31 groups=2 $input=30 #30=(1,116,40,40)f32 #31=(1,116,40,40)f32
torch.chunk              torch.chunk_79           1 2 31 32 33 chunks=2 dim=1 $input=31 #31=(1,116,40,40)f32 #32=(1,58,40,40)f32 #33=(1,58,40,40)f32
nn.Conv2d                convbn2d_12              1 1 33 34 bias=True dilation=(1,1) groups=1 in_channels=58 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,58,1,1)f32 $input=33 #33=(1,58,40,40)f32 #34=(1,58,40,40)f32
nn.LeakyReLU             backbone.stage2.3.branch2.2 1 1 34 35 negative_slope=1.000000e-01 #34=(1,58,40,40)f32 #35=(1,58,40,40)f32
nn.Conv2d                convbn2d_13              1 1 35 36 bias=True dilation=(1,1) groups=58 in_channels=58 kernel_size=(3,3) out_channels=58 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,1,3,3)f32 $input=35 #35=(1,58,40,40)f32 #36=(1,58,40,40)f32
nn.Conv2d                convbn2d_14              1 1 36 37 bias=True dilation=(1,1) groups=1 in_channels=58 kernel_size=(1,1) out_channels=58 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(58)f32 @weight=(58,58,1,1)f32 $input=36 #36=(1,58,40,40)f32 #37=(1,58,40,40)f32
nn.LeakyReLU             backbone.stage2.3.branch2.7 1 1 37 38 negative_slope=1.000000e-01 #37=(1,58,40,40)f32 #38=(1,58,40,40)f32
torch.cat                torch.cat_51             2 1 32 38 39 dim=1 #32=(1,58,40,40)f32 #38=(1,58,40,40)f32 #39=(1,116,40,40)f32
nn.ChannelShuffle        channelshuffle_3         1 1 39 40 groups=2 $input=39 #39=(1,116,40,40)f32 #40=(1,116,40,40)f32
nn.Conv2d                convbn2d_15              1 1 40 41 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=40 #40=(1,116,40,40)f32 #41=(1,116,20,20)f32
nn.Conv2d                convbn2d_16              1 1 41 42 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=41 #41=(1,116,20,20)f32 #42=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.0.branch1.4 1 1 42 43 negative_slope=1.000000e-01 #42=(1,116,20,20)f32 #43=(1,116,20,20)f32
nn.Conv2d                convbn2d_17              1 1 40 44 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=40 #40=(1,116,40,40)f32 #44=(1,116,40,40)f32
nn.LeakyReLU             backbone.stage3.0.branch2.2 1 1 44 45 negative_slope=1.000000e-01 #44=(1,116,40,40)f32 #45=(1,116,40,40)f32
nn.Conv2d                convbn2d_18              1 1 45 46 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=45 #45=(1,116,40,40)f32 #46=(1,116,20,20)f32
nn.Conv2d                convbn2d_19              1 1 46 47 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=46 #46=(1,116,20,20)f32 #47=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.0.branch2.7 1 1 47 48 negative_slope=1.000000e-01 #47=(1,116,20,20)f32 #48=(1,116,20,20)f32
torch.cat                torch.cat_52             2 1 43 48 49 dim=1 #43=(1,116,20,20)f32 #48=(1,116,20,20)f32 #49=(1,232,20,20)f32
nn.ChannelShuffle        channelshuffle_4         1 1 49 50 groups=2 $input=49 #49=(1,232,20,20)f32 #50=(1,232,20,20)f32
torch.chunk              torch.chunk_80           1 2 50 51 52 chunks=2 dim=1 $input=50 #50=(1,232,20,20)f32 #51=(1,116,20,20)f32 #52=(1,116,20,20)f32
nn.Conv2d                convbn2d_20              1 1 52 53 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=52 #52=(1,116,20,20)f32 #53=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.1.branch2.2 1 1 53 54 negative_slope=1.000000e-01 #53=(1,116,20,20)f32 #54=(1,116,20,20)f32
nn.Conv2d                convbn2d_21              1 1 54 55 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=54 #54=(1,116,20,20)f32 #55=(1,116,20,20)f32
nn.Conv2d                convbn2d_22              1 1 55 56 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=55 #55=(1,116,20,20)f32 #56=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.1.branch2.7 1 1 56 57 negative_slope=1.000000e-01 #56=(1,116,20,20)f32 #57=(1,116,20,20)f32
torch.cat                torch.cat_53             2 1 51 57 58 dim=1 #51=(1,116,20,20)f32 #57=(1,116,20,20)f32 #58=(1,232,20,20)f32
nn.ChannelShuffle        channelshuffle_5         1 1 58 59 groups=2 $input=58 #58=(1,232,20,20)f32 #59=(1,232,20,20)f32
torch.chunk              torch.chunk_81           1 2 59 60 61 chunks=2 dim=1 $input=59 #59=(1,232,20,20)f32 #60=(1,116,20,20)f32 #61=(1,116,20,20)f32
nn.Conv2d                convbn2d_23              1 1 61 62 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=61 #61=(1,116,20,20)f32 #62=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.2.branch2.2 1 1 62 63 negative_slope=1.000000e-01 #62=(1,116,20,20)f32 #63=(1,116,20,20)f32
nn.Conv2d                convbn2d_24              1 1 63 64 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=63 #63=(1,116,20,20)f32 #64=(1,116,20,20)f32
nn.Conv2d                convbn2d_25              1 1 64 65 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=64 #64=(1,116,20,20)f32 #65=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.2.branch2.7 1 1 65 66 negative_slope=1.000000e-01 #65=(1,116,20,20)f32 #66=(1,116,20,20)f32
torch.cat                torch.cat_54             2 1 60 66 67 dim=1 #60=(1,116,20,20)f32 #66=(1,116,20,20)f32 #67=(1,232,20,20)f32
nn.ChannelShuffle        channelshuffle_6         1 1 67 68 groups=2 $input=67 #67=(1,232,20,20)f32 #68=(1,232,20,20)f32
torch.chunk              torch.chunk_82           1 2 68 69 70 chunks=2 dim=1 $input=68 #68=(1,232,20,20)f32 #69=(1,116,20,20)f32 #70=(1,116,20,20)f32
nn.Conv2d                convbn2d_26              1 1 70 71 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=70 #70=(1,116,20,20)f32 #71=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.3.branch2.2 1 1 71 72 negative_slope=1.000000e-01 #71=(1,116,20,20)f32 #72=(1,116,20,20)f32
nn.Conv2d                convbn2d_27              1 1 72 73 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=72 #72=(1,116,20,20)f32 #73=(1,116,20,20)f32
nn.Conv2d                convbn2d_28              1 1 73 74 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=73 #73=(1,116,20,20)f32 #74=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.3.branch2.7 1 1 74 75 negative_slope=1.000000e-01 #74=(1,116,20,20)f32 #75=(1,116,20,20)f32
torch.cat                torch.cat_55             2 1 69 75 76 dim=1 #69=(1,116,20,20)f32 #75=(1,116,20,20)f32 #76=(1,232,20,20)f32
nn.ChannelShuffle        channelshuffle_7         1 1 76 77 groups=2 $input=76 #76=(1,232,20,20)f32 #77=(1,232,20,20)f32
torch.chunk              torch.chunk_83           1 2 77 78 79 chunks=2 dim=1 $input=77 #77=(1,232,20,20)f32 #78=(1,116,20,20)f32 #79=(1,116,20,20)f32
nn.Conv2d                convbn2d_29              1 1 79 80 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=79 #79=(1,116,20,20)f32 #80=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.4.branch2.2 1 1 80 81 negative_slope=1.000000e-01 #80=(1,116,20,20)f32 #81=(1,116,20,20)f32
nn.Conv2d                convbn2d_30              1 1 81 82 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=81 #81=(1,116,20,20)f32 #82=(1,116,20,20)f32
nn.Conv2d                convbn2d_31              1 1 82 83 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=82 #82=(1,116,20,20)f32 #83=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.4.branch2.7 1 1 83 84 negative_slope=1.000000e-01 #83=(1,116,20,20)f32 #84=(1,116,20,20)f32
torch.cat                torch.cat_56             2 1 78 84 85 dim=1 #78=(1,116,20,20)f32 #84=(1,116,20,20)f32 #85=(1,232,20,20)f32
nn.ChannelShuffle        channelshuffle_8         1 1 85 86 groups=2 $input=85 #85=(1,232,20,20)f32 #86=(1,232,20,20)f32
torch.chunk              torch.chunk_84           1 2 86 87 88 chunks=2 dim=1 $input=86 #86=(1,232,20,20)f32 #87=(1,116,20,20)f32 #88=(1,116,20,20)f32
nn.Conv2d                convbn2d_32              1 1 88 89 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=88 #88=(1,116,20,20)f32 #89=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.5.branch2.2 1 1 89 90 negative_slope=1.000000e-01 #89=(1,116,20,20)f32 #90=(1,116,20,20)f32
nn.Conv2d                convbn2d_33              1 1 90 91 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=90 #90=(1,116,20,20)f32 #91=(1,116,20,20)f32
nn.Conv2d                convbn2d_34              1 1 91 92 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=91 #91=(1,116,20,20)f32 #92=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.5.branch2.7 1 1 92 93 negative_slope=1.000000e-01 #92=(1,116,20,20)f32 #93=(1,116,20,20)f32
torch.cat                torch.cat_57             2 1 87 93 94 dim=1 #87=(1,116,20,20)f32 #93=(1,116,20,20)f32 #94=(1,232,20,20)f32
nn.ChannelShuffle        channelshuffle_9         1 1 94 95 groups=2 $input=94 #94=(1,232,20,20)f32 #95=(1,232,20,20)f32
torch.chunk              torch.chunk_85           1 2 95 96 97 chunks=2 dim=1 $input=95 #95=(1,232,20,20)f32 #96=(1,116,20,20)f32 #97=(1,116,20,20)f32
nn.Conv2d                convbn2d_35              1 1 97 98 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=97 #97=(1,116,20,20)f32 #98=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.6.branch2.2 1 1 98 99 negative_slope=1.000000e-01 #98=(1,116,20,20)f32 #99=(1,116,20,20)f32
nn.Conv2d                convbn2d_36              1 1 99 100 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=99 #99=(1,116,20,20)f32 #100=(1,116,20,20)f32
nn.Conv2d                convbn2d_37              1 1 100 101 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=100 #100=(1,116,20,20)f32 #101=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.6.branch2.7 1 1 101 102 negative_slope=1.000000e-01 #101=(1,116,20,20)f32 #102=(1,116,20,20)f32
torch.cat                torch.cat_58             2 1 96 102 103 dim=1 #96=(1,116,20,20)f32 #102=(1,116,20,20)f32 #103=(1,232,20,20)f32
nn.ChannelShuffle        channelshuffle_10        1 1 103 104 groups=2 $input=103 #103=(1,232,20,20)f32 #104=(1,232,20,20)f32
torch.chunk              torch.chunk_86           1 2 104 105 106 chunks=2 dim=1 $input=104 #104=(1,232,20,20)f32 #105=(1,116,20,20)f32 #106=(1,116,20,20)f32
nn.Conv2d                convbn2d_38              1 1 106 107 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=106 #106=(1,116,20,20)f32 #107=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.7.branch2.2 1 1 107 108 negative_slope=1.000000e-01 #107=(1,116,20,20)f32 #108=(1,116,20,20)f32
nn.Conv2d                convbn2d_39              1 1 108 109 bias=True dilation=(1,1) groups=116 in_channels=116 kernel_size=(3,3) out_channels=116 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,1,3,3)f32 $input=108 #108=(1,116,20,20)f32 #109=(1,116,20,20)f32
nn.Conv2d                convbn2d_40              1 1 109 110 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=116 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(116)f32 @weight=(116,116,1,1)f32 $input=109 #109=(1,116,20,20)f32 #110=(1,116,20,20)f32
nn.LeakyReLU             backbone.stage3.7.branch2.7 1 1 110 111 negative_slope=1.000000e-01 #110=(1,116,20,20)f32 #111=(1,116,20,20)f32
torch.cat                torch.cat_59             2 1 105 111 112 dim=1 #105=(1,116,20,20)f32 #111=(1,116,20,20)f32 #112=(1,232,20,20)f32
nn.ChannelShuffle        channelshuffle_11        1 1 112 113 groups=2 $input=112 #112=(1,232,20,20)f32 #113=(1,232,20,20)f32
nn.Conv2d                convbn2d_41              1 1 113 114 bias=True dilation=(1,1) groups=232 in_channels=232 kernel_size=(3,3) out_channels=232 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(232)f32 @weight=(232,1,3,3)f32 $input=113 #113=(1,232,20,20)f32 #114=(1,232,10,10)f32
nn.Conv2d                convbn2d_42              1 1 114 115 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=114 #114=(1,232,10,10)f32 #115=(1,232,10,10)f32
nn.LeakyReLU             backbone.stage4.0.branch1.4 1 1 115 116 negative_slope=1.000000e-01 #115=(1,232,10,10)f32 #116=(1,232,10,10)f32
nn.Conv2d                convbn2d_43              1 1 113 117 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=113 #113=(1,232,20,20)f32 #117=(1,232,20,20)f32
nn.LeakyReLU             backbone.stage4.0.branch2.2 1 1 117 118 negative_slope=1.000000e-01 #117=(1,232,20,20)f32 #118=(1,232,20,20)f32
nn.Conv2d                convbn2d_44              1 1 118 119 bias=True dilation=(1,1) groups=232 in_channels=232 kernel_size=(3,3) out_channels=232 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(232)f32 @weight=(232,1,3,3)f32 $input=118 #118=(1,232,20,20)f32 #119=(1,232,10,10)f32
nn.Conv2d                convbn2d_45              1 1 119 120 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=119 #119=(1,232,10,10)f32 #120=(1,232,10,10)f32
nn.LeakyReLU             backbone.stage4.0.branch2.7 1 1 120 121 negative_slope=1.000000e-01 #120=(1,232,10,10)f32 #121=(1,232,10,10)f32
torch.cat                torch.cat_60             2 1 116 121 122 dim=1 #116=(1,232,10,10)f32 #121=(1,232,10,10)f32 #122=(1,464,10,10)f32
nn.ChannelShuffle        channelshuffle_12        1 1 122 123 groups=2 $input=122 #122=(1,464,10,10)f32 #123=(1,464,10,10)f32
torch.chunk              torch.chunk_87           1 2 123 124 125 chunks=2 dim=1 $input=123 #123=(1,464,10,10)f32 #124=(1,232,10,10)f32 #125=(1,232,10,10)f32
nn.Conv2d                convbn2d_46              1 1 125 126 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=125 #125=(1,232,10,10)f32 #126=(1,232,10,10)f32
nn.LeakyReLU             backbone.stage4.1.branch2.2 1 1 126 127 negative_slope=1.000000e-01 #126=(1,232,10,10)f32 #127=(1,232,10,10)f32
nn.Conv2d                convbn2d_47              1 1 127 128 bias=True dilation=(1,1) groups=232 in_channels=232 kernel_size=(3,3) out_channels=232 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,1,3,3)f32 $input=127 #127=(1,232,10,10)f32 #128=(1,232,10,10)f32
nn.Conv2d                convbn2d_48              1 1 128 129 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=128 #128=(1,232,10,10)f32 #129=(1,232,10,10)f32
nn.LeakyReLU             backbone.stage4.1.branch2.7 1 1 129 130 negative_slope=1.000000e-01 #129=(1,232,10,10)f32 #130=(1,232,10,10)f32
torch.cat                torch.cat_61             2 1 124 130 131 dim=1 #124=(1,232,10,10)f32 #130=(1,232,10,10)f32 #131=(1,464,10,10)f32
nn.ChannelShuffle        channelshuffle_13        1 1 131 132 groups=2 $input=131 #131=(1,464,10,10)f32 #132=(1,464,10,10)f32
torch.chunk              torch.chunk_88           1 2 132 133 134 chunks=2 dim=1 $input=132 #132=(1,464,10,10)f32 #133=(1,232,10,10)f32 #134=(1,232,10,10)f32
nn.Conv2d                convbn2d_49              1 1 134 135 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=134 #134=(1,232,10,10)f32 #135=(1,232,10,10)f32
nn.LeakyReLU             backbone.stage4.2.branch2.2 1 1 135 136 negative_slope=1.000000e-01 #135=(1,232,10,10)f32 #136=(1,232,10,10)f32
nn.Conv2d                convbn2d_50              1 1 136 137 bias=True dilation=(1,1) groups=232 in_channels=232 kernel_size=(3,3) out_channels=232 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,1,3,3)f32 $input=136 #136=(1,232,10,10)f32 #137=(1,232,10,10)f32
nn.Conv2d                convbn2d_51              1 1 137 138 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=137 #137=(1,232,10,10)f32 #138=(1,232,10,10)f32
nn.LeakyReLU             backbone.stage4.2.branch2.7 1 1 138 139 negative_slope=1.000000e-01 #138=(1,232,10,10)f32 #139=(1,232,10,10)f32
torch.cat                torch.cat_62             2 1 133 139 140 dim=1 #133=(1,232,10,10)f32 #139=(1,232,10,10)f32 #140=(1,464,10,10)f32
nn.ChannelShuffle        channelshuffle_14        1 1 140 141 groups=2 $input=140 #140=(1,464,10,10)f32 #141=(1,464,10,10)f32
torch.chunk              torch.chunk_89           1 2 141 142 143 chunks=2 dim=1 $input=141 #141=(1,464,10,10)f32 #142=(1,232,10,10)f32 #143=(1,232,10,10)f32
nn.Conv2d                convbn2d_52              1 1 143 144 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=143 #143=(1,232,10,10)f32 #144=(1,232,10,10)f32
nn.LeakyReLU             backbone.stage4.3.branch2.2 1 1 144 145 negative_slope=1.000000e-01 #144=(1,232,10,10)f32 #145=(1,232,10,10)f32
nn.Conv2d                convbn2d_53              1 1 145 146 bias=True dilation=(1,1) groups=232 in_channels=232 kernel_size=(3,3) out_channels=232 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,1,3,3)f32 $input=145 #145=(1,232,10,10)f32 #146=(1,232,10,10)f32
nn.Conv2d                convbn2d_54              1 1 146 147 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=232 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(232)f32 @weight=(232,232,1,1)f32 $input=146 #146=(1,232,10,10)f32 #147=(1,232,10,10)f32
nn.LeakyReLU             backbone.stage4.3.branch2.7 1 1 147 148 negative_slope=1.000000e-01 #147=(1,232,10,10)f32 #148=(1,232,10,10)f32
torch.cat                torch.cat_63             2 1 142 148 149 dim=1 #142=(1,232,10,10)f32 #148=(1,232,10,10)f32 #149=(1,464,10,10)f32
nn.Conv2d                convbn2d_55              1 1 40 150 bias=True dilation=(1,1) groups=1 in_channels=116 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,116,1,1)f32 $input=40 #40=(1,116,40,40)f32 #150=(1,96,40,40)f32
nn.LeakyReLU             fpn.reduce_layers.0.act  1 1 150 151 negative_slope=1.000000e-01 #150=(1,96,40,40)f32 #151=(1,96,40,40)f32
nn.Conv2d                convbn2d_56              1 1 113 152 bias=True dilation=(1,1) groups=1 in_channels=232 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,232,1,1)f32 $input=113 #113=(1,232,20,20)f32 #152=(1,96,20,20)f32
nn.LeakyReLU             fpn.reduce_layers.1.act  1 1 152 153 negative_slope=1.000000e-01 #152=(1,96,20,20)f32 #153=(1,96,20,20)f32
nn.ChannelShuffle        channelshuffle_15        1 1 149 154 groups=2 $input=149 #149=(1,464,10,10)f32 #154=(1,464,10,10)f32
nn.Conv2d                convbn2d_57              1 1 154 155 bias=True dilation=(1,1) groups=1 in_channels=464 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,464,1,1)f32 $input=154 #154=(1,464,10,10)f32 #155=(1,96,10,10)f32
nn.LeakyReLU             fpn.reduce_layers.2.act  1 1 155 156 negative_slope=1.000000e-01 #155=(1,96,10,10)f32 #156=(1,96,10,10)f32
nn.Upsample              fpn.upsample             1 1 156 157 align_corners=False mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) size=None #156=(1,96,10,10)f32 #157=(1,96,20,20)f32
torch.cat                torch.cat_64             2 1 157 153 158 dim=1 #157=(1,96,20,20)f32 #153=(1,96,20,20)f32 #158=(1,192,20,20)f32
nn.Conv2d                convbn2d_58              1 1 158 159 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=48 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,192,1,1)f32 $input=158 #158=(1,192,20,20)f32 #159=(1,48,20,20)f32
nn.LeakyReLU             fpn.top_down_blocks.0.blocks.0.ghost1.primary_conv.2 1 1 159 160 negative_slope=1.000000e-01 #159=(1,48,20,20)f32 #160=(1,48,20,20)f32
nn.Conv2d                convbn2d_59              1 1 160 161 bias=True dilation=(1,1) groups=48 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,1,3,3)f32 $input=160 #160=(1,48,20,20)f32 #161=(1,48,20,20)f32
nn.LeakyReLU             fpn.top_down_blocks.0.blocks.0.ghost1.cheap_operation.2 1 1 161 162 negative_slope=1.000000e-01 #161=(1,48,20,20)f32 #162=(1,48,20,20)f32
torch.cat                torch.cat_65             2 1 160 162 163 dim=1 #160=(1,48,20,20)f32 #162=(1,48,20,20)f32 #163=(1,96,20,20)f32
nn.Conv2d                convbn2d_60              1 1 163 164 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=48 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,96,1,1)f32 $input=163 #163=(1,96,20,20)f32 #164=(1,48,20,20)f32
nn.Conv2d                convbn2d_61              1 1 164 165 bias=True dilation=(1,1) groups=48 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,1,3,3)f32 $input=164 #164=(1,48,20,20)f32 #165=(1,48,20,20)f32
torch.cat                torch.cat_66             2 1 164 165 166 dim=1 #164=(1,48,20,20)f32 #165=(1,48,20,20)f32 #166=(1,96,20,20)f32
nn.Conv2d                convbn2d_62              1 1 158 167 bias=True dilation=(1,1) groups=192 in_channels=192 kernel_size=(5,5) out_channels=192 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,1,5,5)f32 $input=158 #158=(1,192,20,20)f32 #167=(1,192,20,20)f32
nn.Conv2d                convbn2d_63              1 1 167 168 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,192,1,1)f32 $input=167 #167=(1,192,20,20)f32 #168=(1,96,20,20)f32
pnnx.Expression          pnnx_expr_30             2 1 166 168 169 expr=add(@0,@1) #166=(1,96,20,20)f32 #168=(1,96,20,20)f32 #169=(1,96,20,20)f32
nn.Upsample              pnnx_unique_0            1 1 169 170 align_corners=False mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) size=None #169=(1,96,20,20)f32 #170=(1,96,40,40)f32
torch.cat                torch.cat_67             2 1 170 151 171 dim=1 #170=(1,96,40,40)f32 #151=(1,96,40,40)f32 #171=(1,192,40,40)f32
nn.Conv2d                convbn2d_64              1 1 171 172 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=48 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,192,1,1)f32 $input=171 #171=(1,192,40,40)f32 #172=(1,48,40,40)f32
nn.LeakyReLU             fpn.top_down_blocks.1.blocks.0.ghost1.primary_conv.2 1 1 172 173 negative_slope=1.000000e-01 #172=(1,48,40,40)f32 #173=(1,48,40,40)f32
nn.Conv2d                convbn2d_65              1 1 173 174 bias=True dilation=(1,1) groups=48 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,1,3,3)f32 $input=173 #173=(1,48,40,40)f32 #174=(1,48,40,40)f32
nn.LeakyReLU             fpn.top_down_blocks.1.blocks.0.ghost1.cheap_operation.2 1 1 174 175 negative_slope=1.000000e-01 #174=(1,48,40,40)f32 #175=(1,48,40,40)f32
torch.cat                torch.cat_68             2 1 173 175 176 dim=1 #173=(1,48,40,40)f32 #175=(1,48,40,40)f32 #176=(1,96,40,40)f32
nn.Conv2d                convbn2d_66              1 1 176 177 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=48 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,96,1,1)f32 $input=176 #176=(1,96,40,40)f32 #177=(1,48,40,40)f32
nn.Conv2d                convbn2d_67              1 1 177 178 bias=True dilation=(1,1) groups=48 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,1,3,3)f32 $input=177 #177=(1,48,40,40)f32 #178=(1,48,40,40)f32
torch.cat                torch.cat_69             2 1 177 178 179 dim=1 #177=(1,48,40,40)f32 #178=(1,48,40,40)f32 #179=(1,96,40,40)f32
nn.Conv2d                convbn2d_68              1 1 171 180 bias=True dilation=(1,1) groups=192 in_channels=192 kernel_size=(5,5) out_channels=192 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,1,5,5)f32 $input=171 #171=(1,192,40,40)f32 #180=(1,192,40,40)f32
nn.Conv2d                convbn2d_69              1 1 180 181 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,192,1,1)f32 $input=180 #180=(1,192,40,40)f32 #181=(1,96,40,40)f32
pnnx.Expression          pnnx_expr_25             2 1 179 181 182 expr=add(@0,@1) #179=(1,96,40,40)f32 #181=(1,96,40,40)f32 #182=(1,96,40,40)f32
nn.Conv2d                convbn2d_70              1 1 182 183 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(2,2) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=182 #182=(1,96,40,40)f32 #183=(1,96,20,20)f32
nn.LeakyReLU             fpn.downsamples.0.act    1 1 183 184 negative_slope=1.000000e-01 #183=(1,96,20,20)f32 #184=(1,96,20,20)f32
nn.Conv2d                convbn2d_71              1 1 184 185 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=184 #184=(1,96,20,20)f32 #185=(1,96,20,20)f32
nn.LeakyReLU             pnnx_unique_1            1 1 185 186 negative_slope=1.000000e-01 #185=(1,96,20,20)f32 #186=(1,96,20,20)f32
torch.cat                torch.cat_70             2 1 186 169 187 dim=1 #186=(1,96,20,20)f32 #169=(1,96,20,20)f32 #187=(1,192,20,20)f32
nn.Conv2d                convbn2d_72              1 1 187 188 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=48 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,192,1,1)f32 $input=187 #187=(1,192,20,20)f32 #188=(1,48,20,20)f32
nn.LeakyReLU             fpn.bottom_up_blocks.0.blocks.0.ghost1.primary_conv.2 1 1 188 189 negative_slope=1.000000e-01 #188=(1,48,20,20)f32 #189=(1,48,20,20)f32
nn.Conv2d                convbn2d_73              1 1 189 190 bias=True dilation=(1,1) groups=48 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,1,3,3)f32 $input=189 #189=(1,48,20,20)f32 #190=(1,48,20,20)f32
nn.LeakyReLU             fpn.bottom_up_blocks.0.blocks.0.ghost1.cheap_operation.2 1 1 190 191 negative_slope=1.000000e-01 #190=(1,48,20,20)f32 #191=(1,48,20,20)f32
torch.cat                torch.cat_71             2 1 189 191 192 dim=1 #189=(1,48,20,20)f32 #191=(1,48,20,20)f32 #192=(1,96,20,20)f32
nn.Conv2d                convbn2d_74              1 1 192 193 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=48 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,96,1,1)f32 $input=192 #192=(1,96,20,20)f32 #193=(1,48,20,20)f32
nn.Conv2d                convbn2d_75              1 1 193 194 bias=True dilation=(1,1) groups=48 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,1,3,3)f32 $input=193 #193=(1,48,20,20)f32 #194=(1,48,20,20)f32
torch.cat                torch.cat_72             2 1 193 194 195 dim=1 #193=(1,48,20,20)f32 #194=(1,48,20,20)f32 #195=(1,96,20,20)f32
nn.Conv2d                convbn2d_76              1 1 187 196 bias=True dilation=(1,1) groups=192 in_channels=192 kernel_size=(5,5) out_channels=192 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,1,5,5)f32 $input=187 #187=(1,192,20,20)f32 #196=(1,192,20,20)f32
nn.Conv2d                convbn2d_77              1 1 196 197 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,192,1,1)f32 $input=196 #196=(1,192,20,20)f32 #197=(1,96,20,20)f32
pnnx.Expression          pnnx_expr_20             2 1 195 197 198 expr=add(@0,@1) #195=(1,96,20,20)f32 #197=(1,96,20,20)f32 #198=(1,96,20,20)f32
nn.Conv2d                convbn2d_78              1 1 198 199 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(2,2) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=198 #198=(1,96,20,20)f32 #199=(1,96,10,10)f32
nn.LeakyReLU             fpn.downsamples.1.act    1 1 199 200 negative_slope=1.000000e-01 #199=(1,96,10,10)f32 #200=(1,96,10,10)f32
nn.Conv2d                convbn2d_79              1 1 200 201 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=200 #200=(1,96,10,10)f32 #201=(1,96,10,10)f32
nn.LeakyReLU             pnnx_unique_2            1 1 201 202 negative_slope=1.000000e-01 #201=(1,96,10,10)f32 #202=(1,96,10,10)f32
torch.cat                torch.cat_73             2 1 202 156 203 dim=1 #202=(1,96,10,10)f32 #156=(1,96,10,10)f32 #203=(1,192,10,10)f32
nn.Conv2d                convbn2d_80              1 1 203 204 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=48 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,192,1,1)f32 $input=203 #203=(1,192,10,10)f32 #204=(1,48,10,10)f32
nn.LeakyReLU             fpn.bottom_up_blocks.1.blocks.0.ghost1.primary_conv.2 1 1 204 205 negative_slope=1.000000e-01 #204=(1,48,10,10)f32 #205=(1,48,10,10)f32
nn.Conv2d                convbn2d_81              1 1 205 206 bias=True dilation=(1,1) groups=48 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,1,3,3)f32 $input=205 #205=(1,48,10,10)f32 #206=(1,48,10,10)f32
nn.LeakyReLU             fpn.bottom_up_blocks.1.blocks.0.ghost1.cheap_operation.2 1 1 206 207 negative_slope=1.000000e-01 #206=(1,48,10,10)f32 #207=(1,48,10,10)f32
torch.cat                torch.cat_74             2 1 205 207 208 dim=1 #205=(1,48,10,10)f32 #207=(1,48,10,10)f32 #208=(1,96,10,10)f32
nn.Conv2d                convbn2d_82              1 1 208 209 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=48 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,96,1,1)f32 $input=208 #208=(1,96,10,10)f32 #209=(1,48,10,10)f32
nn.Conv2d                convbn2d_83              1 1 209 210 bias=True dilation=(1,1) groups=48 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,1,3,3)f32 $input=209 #209=(1,48,10,10)f32 #210=(1,48,10,10)f32
torch.cat                torch.cat_75             2 1 209 210 211 dim=1 #209=(1,48,10,10)f32 #210=(1,48,10,10)f32 #211=(1,96,10,10)f32
nn.Conv2d                convbn2d_84              1 1 203 212 bias=True dilation=(1,1) groups=192 in_channels=192 kernel_size=(5,5) out_channels=192 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,1,5,5)f32 $input=203 #203=(1,192,10,10)f32 #212=(1,192,10,10)f32
nn.Conv2d                convbn2d_85              1 1 212 213 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,192,1,1)f32 $input=212 #212=(1,192,10,10)f32 #213=(1,96,10,10)f32
pnnx.Expression          pnnx_expr_15             2 1 211 213 214 expr=add(@0,@1) #211=(1,96,10,10)f32 #213=(1,96,10,10)f32 #214=(1,96,10,10)f32
nn.Conv2d                convbn2d_86              1 1 156 215 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(2,2) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=156 #156=(1,96,10,10)f32 #215=(1,96,5,5)f32
nn.LeakyReLU             fpn.extra_lvl_in_conv.0.act 1 1 215 216 negative_slope=1.000000e-01 #215=(1,96,5,5)f32 #216=(1,96,5,5)f32
nn.Conv2d                convbn2d_87              1 1 216 217 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=216 #216=(1,96,5,5)f32 #217=(1,96,5,5)f32
nn.LeakyReLU             pnnx_unique_3            1 1 217 218 negative_slope=1.000000e-01 #217=(1,96,5,5)f32 #218=(1,96,5,5)f32
nn.Conv2d                convbn2d_88              1 1 214 219 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(2,2) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=214 #214=(1,96,10,10)f32 #219=(1,96,5,5)f32
nn.LeakyReLU             fpn.extra_lvl_out_conv.0.act 1 1 219 220 negative_slope=1.000000e-01 #219=(1,96,5,5)f32 #220=(1,96,5,5)f32
nn.Conv2d                convbn2d_89              1 1 220 221 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=220 #220=(1,96,5,5)f32 #221=(1,96,5,5)f32
nn.LeakyReLU             pnnx_unique_4            1 1 221 222 negative_slope=1.000000e-01 #221=(1,96,5,5)f32 #222=(1,96,5,5)f32
pnnx.Expression          pnnx_expr_13             2 1 218 222 223 expr=add(@0,@1) #218=(1,96,5,5)f32 #222=(1,96,5,5)f32 #223=(1,96,5,5)f32
nn.Conv2d                convbn2d_90              1 1 182 224 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=182 #182=(1,96,40,40)f32 #224=(1,96,40,40)f32
nn.LeakyReLU             head.cls_convs.0.0.act   1 1 224 225 negative_slope=1.000000e-01 #224=(1,96,40,40)f32 #225=(1,96,40,40)f32
nn.Conv2d                convbn2d_91              1 1 225 226 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=225 #225=(1,96,40,40)f32 #226=(1,96,40,40)f32
nn.LeakyReLU             pnnx_unique_5            1 1 226 227 negative_slope=1.000000e-01 #226=(1,96,40,40)f32 #227=(1,96,40,40)f32
nn.Conv2d                convbn2d_92              1 1 227 228 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=227 #227=(1,96,40,40)f32 #228=(1,96,40,40)f32
nn.LeakyReLU             head.cls_convs.0.1.act   1 1 228 229 negative_slope=1.000000e-01 #228=(1,96,40,40)f32 #229=(1,96,40,40)f32
nn.Conv2d                convbn2d_93              1 1 229 230 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=229 #229=(1,96,40,40)f32 #230=(1,96,40,40)f32
nn.LeakyReLU             pnnx_unique_6            1 1 230 231 negative_slope=1.000000e-01 #230=(1,96,40,40)f32 #231=(1,96,40,40)f32
nn.Conv2d                head.gfl_cls.0           1 1 231 232 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=112 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(112)f32 @weight=(112,96,1,1)f32 #231=(1,96,40,40)f32 #232=(1,112,40,40)f32
nn.Conv2d                convbn2d_94              1 1 198 233 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=198 #198=(1,96,20,20)f32 #233=(1,96,20,20)f32
nn.LeakyReLU             head.cls_convs.1.0.act   1 1 233 234 negative_slope=1.000000e-01 #233=(1,96,20,20)f32 #234=(1,96,20,20)f32
nn.Conv2d                convbn2d_95              1 1 234 235 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=234 #234=(1,96,20,20)f32 #235=(1,96,20,20)f32
nn.LeakyReLU             pnnx_unique_7            1 1 235 236 negative_slope=1.000000e-01 #235=(1,96,20,20)f32 #236=(1,96,20,20)f32
nn.Conv2d                convbn2d_96              1 1 236 237 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=236 #236=(1,96,20,20)f32 #237=(1,96,20,20)f32
nn.LeakyReLU             head.cls_convs.1.1.act   1 1 237 238 negative_slope=1.000000e-01 #237=(1,96,20,20)f32 #238=(1,96,20,20)f32
nn.Conv2d                convbn2d_97              1 1 238 239 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=238 #238=(1,96,20,20)f32 #239=(1,96,20,20)f32
nn.LeakyReLU             pnnx_unique_8            1 1 239 240 negative_slope=1.000000e-01 #239=(1,96,20,20)f32 #240=(1,96,20,20)f32
nn.Conv2d                head.gfl_cls.1           1 1 240 241 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=112 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(112)f32 @weight=(112,96,1,1)f32 #240=(1,96,20,20)f32 #241=(1,112,20,20)f32
nn.Conv2d                convbn2d_98              1 1 214 242 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=214 #214=(1,96,10,10)f32 #242=(1,96,10,10)f32
nn.LeakyReLU             head.cls_convs.2.0.act   1 1 242 243 negative_slope=1.000000e-01 #242=(1,96,10,10)f32 #243=(1,96,10,10)f32
nn.Conv2d                convbn2d_99              1 1 243 244 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=243 #243=(1,96,10,10)f32 #244=(1,96,10,10)f32
nn.LeakyReLU             pnnx_unique_9            1 1 244 245 negative_slope=1.000000e-01 #244=(1,96,10,10)f32 #245=(1,96,10,10)f32
nn.Conv2d                convbn2d_100             1 1 245 246 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=245 #245=(1,96,10,10)f32 #246=(1,96,10,10)f32
nn.LeakyReLU             head.cls_convs.2.1.act   1 1 246 247 negative_slope=1.000000e-01 #246=(1,96,10,10)f32 #247=(1,96,10,10)f32
nn.Conv2d                convbn2d_101             1 1 247 248 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=247 #247=(1,96,10,10)f32 #248=(1,96,10,10)f32
nn.LeakyReLU             pnnx_unique_10           1 1 248 249 negative_slope=1.000000e-01 #248=(1,96,10,10)f32 #249=(1,96,10,10)f32
nn.Conv2d                head.gfl_cls.2           1 1 249 250 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=112 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(112)f32 @weight=(112,96,1,1)f32 #249=(1,96,10,10)f32 #250=(1,112,10,10)f32
nn.Conv2d                convbn2d_102             1 1 223 251 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=223 #223=(1,96,5,5)f32 #251=(1,96,5,5)f32
nn.LeakyReLU             head.cls_convs.3.0.act   1 1 251 252 negative_slope=1.000000e-01 #251=(1,96,5,5)f32 #252=(1,96,5,5)f32
nn.Conv2d                convbn2d_103             1 1 252 253 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=252 #252=(1,96,5,5)f32 #253=(1,96,5,5)f32
nn.LeakyReLU             pnnx_unique_11           1 1 253 254 negative_slope=1.000000e-01 #253=(1,96,5,5)f32 #254=(1,96,5,5)f32
nn.Conv2d                convbn2d_104             1 1 254 255 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(5,5) out_channels=96 padding=(2,2) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,1,5,5)f32 $input=254 #254=(1,96,5,5)f32 #255=(1,96,5,5)f32
nn.LeakyReLU             head.cls_convs.3.1.act   1 1 255 256 negative_slope=1.000000e-01 #255=(1,96,5,5)f32 #256=(1,96,5,5)f32
nn.Conv2d                convbn2d_105             1 1 256 257 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,1,1)f32 $input=256 #256=(1,96,5,5)f32 #257=(1,96,5,5)f32
nn.LeakyReLU             pnnx_unique_12           1 1 257 258 negative_slope=1.000000e-01 #257=(1,96,5,5)f32 #258=(1,96,5,5)f32
nn.Conv2d                head.gfl_cls.3           1 1 258 259 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=112 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(112)f32 @weight=(112,96,1,1)f32 #258=(1,96,5,5)f32 #259=(1,112,5,5)f32
torch.flatten            torch.flatten_93         1 1 259 260 end_dim=-1 start_dim=2 $input=259 #259=(1,112,5,5)f32 #260=(1,112,25)f32
torch.flatten            torch.flatten_92         1 1 250 261 end_dim=-1 start_dim=2 $input=250 #250=(1,112,10,10)f32 #261=(1,112,100)f32
torch.flatten            torch.flatten_91         1 1 241 262 end_dim=-1 start_dim=2 $input=241 #241=(1,112,20,20)f32 #262=(1,112,400)f32
torch.flatten            torch.flatten_90         1 1 232 263 end_dim=-1 start_dim=2 $input=232 #232=(1,112,40,40)f32 #263=(1,112,1600)f32
torch.cat                torch.cat_76             4 1 263 262 261 260 264 dim=2 #263=(1,112,1600)f32 #262=(1,112,400)f32 #261=(1,112,100)f32 #260=(1,112,25)f32 #264=(1,112,2125)f32
torch.permute            torch.permute_94         1 1 264 265 dims=(0,2,1) $input=264 #264=(1,112,2125)f32 #265=(1,2125,112)f32
pnnx.Output              pnnx_output_0            1 0 265 #265=(1,2125,112)f32
